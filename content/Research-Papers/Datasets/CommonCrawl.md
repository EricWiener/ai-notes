---
tags:
  - flashcards
source: https://commoncrawl.org/
summary: Free dataset of web crawl data
---
Common Crawl maintains a free, open repository of web crawl data that can be used by anyone. It is the primary training corpus in every LLM.

It produces about 20TB of text data extracted from web pages each month. (Source: [[Research-Papers/Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer|Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer]]).
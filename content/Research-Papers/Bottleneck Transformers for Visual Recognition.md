---
tags: [flashcards]
source:
summary: By just replacing the spatial convolutions with global self-attention in the final three bottleneck blocks of a ResNet and no other changes, our approach improves upon the baselines significantly on instance segmentation and object detection while also reducing the parameters, with minimal overhead in latency.
---

[[Bottleneck Transformers for Visual Recognition, Aravind Srinivas et al., 2021.pdf]]

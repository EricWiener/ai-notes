---
tags: [flashcards]
source: https://arxiv.org/abs/1708.02551
summary: Mask R-CNN extends Faster R-CNN with a parallel head to predict per-class binary masks for each region o
---

- Mask R-CNN is an instance segmentation model that has two parallel heads: one to predict bounding boxes with class labels and another to predict class-agnostic segmentation masks.
- The model functions the same as [[Faster R-CNN]] but just adds on predicting a mask.
- Mask R-CNN uses [[RoI Align]] instead of [[ROI Pooling]] in order to reduce quantization error since mask predictions need to be more fine-grained than bounding box predictions.
- Mask R-CNN needs huge amounts of training data.

# Related Work
- Previous works used a two-stage approach where a number of segment proposals are made, which is then followed by a voting between those proposals to choose the best. The segmentation comes before the classification (vs. in parallel), so these approaches are slower. Source: [[UPSNet]].
- Mask R-CNN predicts masks and boxes + labels in parallel so it can run faster than the two-stage models.

# Architecture

![[mask-rcnn-w-out-mask-head.png]]
Above is the traditional [[Faster R-CNN]] architecture. You have a CONV backbone and extract image features. You then pass these features to a region proposal network and get region proposals. Using RoI Align, you then crop the feature map from the CONV backbone for each region from the region proposal network. You then predict a class label and 4 values for the bounding box transform for each point in the feature grid.

![[mask-rcnn-diagram.png]]

Mask R-CNN adds on a mask head that predicts a binary segmentation mask for each ==region of interest==. It predicts a mask for each of the $C$ classes. In the above example, the region of interest is cropped from the original feature map generated by the CONV backbone and re-sized to a $14 \times 14$ patch (with 256 channels). This is then passed through a 1x1 conv and you end up with $256 \times 14 \times 14$ feature map. This is then passed through additional conv layers and you end up with mask predictions for each of the $C$ classes per-pixel location. 
<!--SR:!2023-12-18,233,250-->

Mask R-CNN predicts the masks ==in parallel== to the bounding boxes and classes. This decouples mask and class prediction and led to good instance segmentation results.
<!--SR:!2026-11-03,1073,330-->

Note: the model makes masks predictions for every category, but during training we only supervise the predictions for the ground truth category for that object. This is because the paper "found it essential to _decouple_ mask and class prediction: we predict a binary mask for each class independently, without competition among classes, and rely on the network’s RoI classification branch to predict the category. In contrast, FCNs usually perform per-pixel multi-class categorization, which couples segmentation and classification, and based on our experiments works poorly for instance segmentation."

# Variants
- You can use different backbones and different heads (like [[Object Detection#Feature Pyramid Network]]).
- Depending on the task, you might be better off with a higher resolution mask. The Mask R-CNN paper achieves this with [[Transposed Convolution]] and [[Upsampling#Bilinear Interpolation Upsampling]]. 

---
tags: [flashcards]
aliases: [Markov Process]
source: https://en.wikipedia.org/wiki/Markov_chain
summary: a probabilistic series of events where the probability of each event depends only on the state of the previous event
---

A Markov chain or Markov process is a stochastic model describing a sequence of possible events in which the probability of each event depends ==only on the state attained in the previous event==. Informally, this may be thought of as, "What happens next depends only on the state of affairs now."
<!--SR:!2025-01-16,446,330-->

Stochastic means having a ==random probability distribution== or pattern that may be analyzed statistically but may not be predicted precisely.
<!--SR:!2024-12-21,420,310-->